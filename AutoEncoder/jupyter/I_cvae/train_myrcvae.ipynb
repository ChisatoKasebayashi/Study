{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CVAE on MNIST\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import chainer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import net \n",
    "import make_random_mnist\n",
    "import make_random_selfdata\n",
    "from chainer import serializers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg = '../images/inu.png'\\ndataset = make_random_selfdata.MakeRandomSelfdata(img)    \\ntest = dataset.get_random_dataset_with_one_hot_vector_2d(2)\\n\\n#print(len(test[0][0])) # 28*28\\n#print(len(test[0][1])) # cropできる領域の面積 one hot vec 3277\\n\\ndef make_gentle_onehot_vec(hotvec):\\n    g_hotvec = hotvec.copy()\\n    deviation = 20\\n    random_nun = 5000\\n    hotvec_l = hotvec.tolist()\\n    average = hotvec_l.index(1)\\n    g_hotvec[average] = 0\\n    rand_n = np.random.normal(average, deviation, random_nun)\\n    for n in range(random_nun):\\n        index = rand_n[n].astype('int32')\\n        if(index<0 or len(hotvec_l)<=index):\\n            continue\\n        g_hotvec[index] = g_hotvec[index] + 1\\n    ret = g_hotvec/max(g_hotvec)\\n    return ret\\n\\ng_hotvec = make_gentle_onehot_vec(test[0][1])\\nprint(g_hotvec)\\nplt.plot(g_hotvec)\\nplt.bar(range(len(g_hotvec)), g_hotvec)\\nhotvec_l = test[0][1].tolist()\\n#plt.xlim([hotvec_l.index(1)-20, hotvec_l.index(1)+20])\\nave = 8\\ndeviation = 10\\nrandom_nun = 10000\\nrand_n = np.random.normal(ave, deviation, random_nun)\\nrand_n = rand_n.astype('int32')\\n\\nplt.bar(rand_n,range())#,bins=100)\\n#plt.xlim([ave-10,ave+10])\\nplt.show()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img = '../images/inu.png'\n",
    "dataset = make_random_selfdata.MakeRandomSelfdata(img)    \n",
    "test = dataset.get_random_dataset_with_one_hot_vector_2d(2)\n",
    "\n",
    "#print(len(test[0][0])) # 28*28\n",
    "#print(len(test[0][1])) # cropできる領域の面積 one hot vec 3277\n",
    "\n",
    "def make_gentle_onehot_vec(hotvec):\n",
    "    g_hotvec = hotvec.copy()\n",
    "    deviation = 20\n",
    "    random_nun = 5000\n",
    "    hotvec_l = hotvec.tolist()\n",
    "    average = hotvec_l.index(1)\n",
    "    g_hotvec[average] = 0\n",
    "    rand_n = np.random.normal(average, deviation, random_nun)\n",
    "    for n in range(random_nun):\n",
    "        index = rand_n[n].astype('int32')\n",
    "        if(index<0 or len(hotvec_l)<=index):\n",
    "            continue\n",
    "        g_hotvec[index] = g_hotvec[index] + 1\n",
    "    ret = g_hotvec/max(g_hotvec)\n",
    "    return ret\n",
    "\n",
    "g_hotvec = make_gentle_onehot_vec(test[0][1])\n",
    "print(g_hotvec)\n",
    "plt.plot(g_hotvec)\n",
    "plt.bar(range(len(g_hotvec)), g_hotvec)\n",
    "hotvec_l = test[0][1].tolist()\n",
    "#plt.xlim([hotvec_l.index(1)-20, hotvec_l.index(1)+20])\n",
    "ave = 8\n",
    "deviation = 10\n",
    "random_nun = 10000\n",
    "rand_n = np.random.normal(ave, deviation, random_nun)\n",
    "rand_n = rand_n.astype('int32')\n",
    "\n",
    "plt.bar(rand_n,range())#,bins=100)\n",
    "#plt.xlim([ave-10,ave+10])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def save_images(x, filename,cols=3,rows=3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(cols, rows, figsize=(9, 9), dpi=100, edgecolor='coral', linewidth=2)\n",
    "    for ai, xi in zip(ax.ravel(), x):\n",
    "        ai.imshow(xi.reshape(28, 28))\n",
    "    ai.set_title(filename)\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "def save_onehotvec(x):\n",
    "    plt.plot(x)\n",
    "    plt.show()\n",
    "    \n",
    "def trainMyModel(model, x_train, x_test, options):\n",
    "    if options.test:\n",
    "        x_train, _ = chainer.datasets.split_dataset(x_train, 100)\n",
    "        x_test, _ = chainer.datasets.split_dataset(x_test, 100)\n",
    "    train_iter = chainer.iterators.SerialIterator(x_train, options.batchsize)\n",
    "    test_iter = chainer.iterators.SerialIterator(x_test, options.batchsize,repeat=False, shuffle=False)\n",
    "    \n",
    "    # Setup an optimizer\n",
    "    optimizer = chainer.optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    # Initialize\n",
    "    if options.initmodel:\n",
    "        chainer.serializers.load_npz(options.initmodel, model)\n",
    "\n",
    "    # Set up an updater. StandardUpdater can explicitly specify a loss function\n",
    "    # used in the training with 'loss_func' option\n",
    "    updater = training.updaters.StandardUpdater(train_iter, optimizer,device=options.gpu, loss_func=model.get_loss_func())\n",
    "\n",
    "    trainer = training.Trainer(updater, (options.epoch, 'epoch'), out=options.out)\n",
    "    trainer.extend(extensions.Evaluator(test_iter, model, device=options.gpu,eval_func=model.get_loss_func(k=10)))\n",
    "    trainer.extend(extensions.dump_graph('main/loss'))\n",
    "    trainer.extend(extensions.snapshot(), trigger=(20, 'epoch'))\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'main/loss', 'validation/main/loss',\n",
    "         'main/rec_loss', 'validation/main/rec_loss', 'elapsed_time']))\n",
    "    #trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "    if options.resume:\n",
    "        chainer.serializers.load_npz(options.resume, trainer)\n",
    "\n",
    "    # Run the training\n",
    "    trainer.run()\n",
    "    model.to_cpu()\n",
    "    serializers.save_npz(\"mymodel_final.npz\", model)\n",
    "    return model\n",
    "\n",
    "def testMyModel(model, x_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_random_dataset_withlabel(fname, n):\n",
    "    dataset = make_random_mnist.MakeRandomMNIST()\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, mode='rb') as f:\n",
    "            ret = pickle.load(f)\n",
    "            return ret\n",
    "    v = dataset.get_random_dataset_with_label(n)\n",
    "    with open(fname, mode='wb') as f:\n",
    "        pickle.dump(v, f)\n",
    "        return v\n",
    "\n",
    "def dispImage(img_vec):\n",
    "    #title = 'Label number is ('+ str(label_x) + ',' + str(label_y) + ')' \n",
    "    pixels = (img_vec * 256).reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    #plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def dispOneHotVec(img, vec, vec_size,vec_ratio):\n",
    "    t_img = img.copy() # cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "    #print(np.where(vec==1))\n",
    "    hotvec = vec.reshape(vec_size)\n",
    "    #print(hotvec.shape)\n",
    "    cx, cy = np.where(hotvec == 1)\n",
    "    #print(cx, cy)\n",
    "    conv_img_coord_x = (cy*vec_ratio)+14\n",
    "    conv_img_coord_y = (cx*vec_ratio)+14\n",
    "    t_img = cv2.circle(t_img, (conv_img_coord_x,conv_img_coord_y), 1, (255, 0, 0), thickness=-1, lineType=cv2.LINE_8, shift=0)\n",
    "    t_img = cv2.rectangle(t_img, (conv_img_coord_x-14,conv_img_coord_y-14), \n",
    "                          (conv_img_coord_x+14,conv_img_coord_y+14), (255,0,0), thickness=0, lineType=cv2.LINE_8, shift=0)\n",
    "    fig = plt.figure() # Figureオブジェクトを作成\n",
    "    ax = fig.add_subplot(1,1,1) # figに属するAxesオブジェクトを作成\n",
    "    plt.imshow(t_img)\n",
    "    plt.show()\n",
    "def dispCropPos(img, data, label_vec_size, vec_ratio, color=(248,169,0)):\n",
    "    t_img = img.copy()\n",
    "    for n in range(len(data)):\n",
    "        im, la = data[n]\n",
    "        #print(la.shape)\n",
    "        hotvec = la.reshape(label_vec_size)\n",
    "        cx, cy = np.where(hotvec == 1)\n",
    "        conv_img_coord_x = (cy*vec_ratio)+14\n",
    "        conv_img_coord_y = (cx*vec_ratio)+14\n",
    "        t_img[conv_img_coord_y, conv_img_coord_x] = color\n",
    "    return t_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chageBrightness(data, label_vec_size):\n",
    "    data_num = len(data)\n",
    "    images = np.zeros((data_num, 28*28), dtype=np.float32)  \n",
    "    labels = np.zeros((data_num, label_vec_size[0]*label_vec_size[1]), dtype=np.float32)  \n",
    "    for i in range(data_num):\n",
    "        img, label = data[i]\n",
    "        rand_gain = np.random.uniform(-0.3, 0.3, (28*28))\n",
    "        im = img+rand_gain\n",
    "        # 0 miman\n",
    "        im = np.where(im > 1, 1, im)\n",
    "        # 1 izyou\n",
    "        im = np.where(im < 0, 0, im)\n",
    "        images[i, :] = im\n",
    "        labels[i, :] = label\n",
    "    return chainer.datasets.TupleDataset(images, labels)\n",
    "\n",
    "def addGomashio(data, label_vec_size):\n",
    "    size = 1\n",
    "    data_num = len(data)\n",
    "    images = np.zeros((data_num, 28*28), dtype=np.float32)  \n",
    "    labels = np.zeros((data_num, label_vec_size[0]*label_vec_size[1]), dtype=np.float32)  \n",
    "    for n in range(data_num):\n",
    "        x = int(np.random.uniform(0,27))\n",
    "        y = int(np.random.uniform(0,27))\n",
    "        c = int(np.random.uniform(0,256))\n",
    "        img, label = data[n]\n",
    "        img = (img * 256).reshape((28, 28))\n",
    "        img = cv2.rectangle(img, (x, y),(x+size,y+size), c, -1)\n",
    "        img = img.flatten()\n",
    "        images[n, :] = img/256.\n",
    "        labels[n, :] = label\n",
    "    return chainer.datasets.TupleDataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "# dim z: 2\n",
      "# Minibatch-size: 200\n",
      "# epoch: 15\n",
      "\n",
      "CONDITION 784\n",
      "CONTEXT 4061\n",
      "epoch       main/loss   validation/main/loss  main/rec_loss  validation/main/rec_loss  elapsed_time\n",
      "\u001b[J1           1071.44     637.303               1048.79        623.132                   0.521319      \n",
      "\u001b[J2           622.101     592.278               612.631        590.797                   1.03264       \n",
      "\u001b[J3           572.012     549.55                569.626        546.799                   1.54645       \n",
      "\u001b[J4           530.978     513.007               528.175        509.978                   2.06027       \n",
      "\u001b[J5           501.304     489.506               498.14         486.294                   2.57439       \n",
      "\u001b[J6           479.598     470.586               476.559        467.502                   3.08875       \n",
      "\u001b[J7           460.615     454.258               457.321        450.938                   3.60226       \n",
      "\u001b[J8           444.806     440.422               441.269        436.777                   4.11675       \n",
      "\u001b[J9           432.328     429.546               428.649        425.776                   4.62843       \n",
      "\u001b[J10          422.25      420.11                418.455        416.295                   5.14218       \n",
      "\u001b[J11          412.788     412.118               409.016        408.207                   5.65429       \n",
      "\u001b[J12          405.12      404.405               401.212        400.644                   6.16653       \n",
      "\u001b[J13          396.341     397.438               392.403        393.646                   6.68051       \n",
      "\u001b[J14          388.828     389.61                384.946        385.684                   7.19565       \n",
      "\u001b[J15          381.14      383.348               377.169        379.175                   7.70728       \n",
      "(4061,)\n",
      "(4061,)\n",
      "x ha kore (4061,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f80407bb34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-5f80407bb34d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x ha kore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m#print('CONTEXTDIM ha kore', CONTEXTDIM.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mxin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTEXTDIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mxout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTEXTDIM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/AutoEncoder/jupyter/I_cvae/net.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, sigmoid)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"\"\"AutoEncoder\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/AutoEncoder/jupyter/I_cvae/net.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle1_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/link.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Call forward_postprocess hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/links/connection/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_batch_axes)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0min_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_batch_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/functions/connection/linear.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(x, W, b, n_batch_axes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_batch_axes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[0;34m(self, in_data)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlight_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/chainer/functions/connection/linear.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[0;34m(self, in_types)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mw_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mw_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         )\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global NLABELDIM, NZDIM\n",
    "    parser = argparse.ArgumentParser(description='Chainer example: VAE')\n",
    "    parser.add_argument('--initmodel', '-m', default='',\n",
    "                        help='Initialize the model from given file')\n",
    "    parser.add_argument('--resume', '-r', default='',\n",
    "                        help='Resume the optimization from snapshot')\n",
    "    parser.add_argument('--gpu', '-g', default=-1, type=int,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--out', '-o', default='result',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--epoch', '-e', default=15, type=int,\n",
    "                        help='number of epochs to learn')\n",
    "    parser.add_argument('--dimz', '-z', default=2, type=int,\n",
    "                        help='dimention of encoded vector')\n",
    "    parser.add_argument('--batchsize', '-b', type=int, default=200,\n",
    "                        help='learning minibatch size')\n",
    "    parser.add_argument('--test', action='store_true',\n",
    "                        help='Use tiny datasets for quick tests')\n",
    "    args = parser.parse_args(args=['-g 0'])\n",
    "\n",
    "    print('GPU: {}'.format(args.gpu))\n",
    "    print('# dim z: {}'.format(args.dimz))\n",
    "    print('# Minibatch-size: {}'.format(args.batchsize))\n",
    "    print('# epoch: {}'.format(args.epoch))\n",
    "    print('')\n",
    "\n",
    "    #img = '../images/chizu_naga.png'\n",
    "    img = '../images/inu.png'\n",
    "    dataset = make_random_selfdata.MakeRandomSelfdata(img)    \n",
    "    global train,test\n",
    "    train = dataset.get_random_dataset_for_rcvae(3000)\n",
    "    test = dataset.get_random_dataset_for_rcvae(3000)\n",
    "    \n",
    "    # Prepare CVAE model, defined in net.py\n",
    "    NLABELDIM = len(train[0][1])\n",
    "    CONTEXTDIM = len(train[0][0])\n",
    "    print('CONDITION', NLABELDIM)\n",
    "    print('CONTEXT', CONTEXTDIM)\n",
    "    NZDIM = args.dimz\n",
    "\n",
    "    model = net.MyCVAE(CONTEXTDIM, args.dimz, 500, NLABELDIM)\n",
    "    model = trainMyModel(model,train,test,args)\n",
    "    \n",
    "    train_ind = [1, 3, 5, 10, 2, 0, 13, 15, 17]\n",
    "    xin = np.empty((0, CONTEXTDIM), np.float32)\n",
    "    xout = np.empty((0, CONTEXTDIM-28*28), np.float32)\n",
    "    for ind in train_ind:\n",
    "        x, t = train[ind]\n",
    "        print(x.shape)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "        print(x.shape)\n",
    "        t = np.expand_dims(t.astype(np.float32), axis=0)\n",
    "        #t = np.eye(NLABELDIM, dtype=np.float32)[t * NLABELDIM]\n",
    "        with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "            print('x ha kore',x.shape)\n",
    "            #print('CONTEXTDIM ha kore', CONTEXTDIM.shape)\n",
    "            x1 = model(x, t, axis=0)\n",
    "            xin = np.append(CONTEXTDIM, x, axis=0)\n",
    "            xout = np.append(CONTEXTDIM-28*28, x1.data, axis=0)\n",
    "    save_images(xin, os.path.join(args.out, 'train'))\n",
    "    save_images(xout, os.path.join(args.out, 'train_reconstructed'))\n",
    "\n",
    "    test_ind = [3, 2, 1, 18, 4, 8, 11, 17, 61]\n",
    "    xin = np.empty((0, CONTEXTDIM), np.float32)\n",
    "    xout = np.empty((0, CONTEXTDIM-28*28), np.float32)\n",
    "    for ind in test_ind:\n",
    "        x, t = test[ind]\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        t = np.expand_dims(t.astype(np.float32), axis=0)\n",
    "        #t = np.eye(NLABELDIM, dtype=np.float32)[t * NLABELDIM]\n",
    "        with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
    "            x1 = model(x, np.expand_dims(t, axis=0))\n",
    "            xin = np.append(CONTEXTDIM, x, axis=0)\n",
    "            xout = np.append(CONTEXTDIM-28*28, x1.data, axis=0)\n",
    "\n",
    "    save_images(xin, os.path.join(args.out, 'test'))\n",
    "    save_images(xout, os.path.join(args.out, 'test_reconstructed'))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conditionで画像を生成するための共通の部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NZDIM = 2\n",
    "NLABELDIM = len(train[0][1])\n",
    "CONTEXTDIM = len(train[0][0])\n",
    "model = net.MyCVAE(CONTEXTDIM, NZDIM, 500, NLABELDIM)\n",
    "serializers.load_npz(\"mymodel_final.npz\", model)\n",
    "# draw images from randomly sampled z\n",
    "#z = chainer.Variable(np.random.normal(0, 1, (10, NZDIM)).astype(np.float32))\n",
    "z = chainer.Variable(np.zeros((10, NZDIM), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28ｘ28の画像が2x5で並んでる訓練画像用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#'''\n",
    "img = '../images/inu.png'\n",
    "t_img = cv2.imread(img)\n",
    "dataset = make_random_selfdata.MakeRandomSelfdata(img)\n",
    "onehot_size = dataset.getOnehotSize()\n",
    "labels = np.zeros((10, onehot_size[0]*onehot_size[1]), dtype=np.float32)       # one hot vector\n",
    "images = np.zeros((10, 28*28), dtype=np.float32)       # condition\n",
    "\n",
    "#'''\n",
    "###########画像の中心を見る用#############　\n",
    "for r in range(2):\n",
    "    for c in range(5):\n",
    "        l = dataset.getLabel(28*c+14, 28*r+14)\n",
    "        i = dataset.getImage(l[0], l[1])\n",
    "        dispOneHotVec(t_img, l,dataset.getOnehotSize(),dataset.onehot_ratio)\n",
    "        labels[r*5+c, :] = l\n",
    "        images[r*5+c, :] = np.reshape(i, 28*28)\n",
    "values = images\n",
    "x1 = model.decode(z, np.expand_dims(values, axis=1))\n",
    "save_onehotvec(x1.data[8])\n",
    "\n",
    "#'''\n",
    "\n",
    "#'''###########細かいとこを見る用#############　\n",
    "\n",
    "s = 100\n",
    "for i in range(s,s+10):\n",
    "    l = dataset.getLabel(i+14, 0+14)\n",
    "    dispOneHotVec(t_img, l,dataset.getOnehotSize(),dataset.onehot_ratio)\n",
    "    labels[i-s, :] = l\n",
    "values = labels\n",
    "x = model.decode(z, np.expand_dims(values, axis=1))\n",
    "save_images(x.data, 'sampled',2, 5)\n",
    "#'''\n",
    "\n",
    "#t_test = np.zeros((10,28*28)), labels\n",
    "t_test = chainer.datasets.TupleDataset(np.zeros((10,28*28)), labels)\n",
    "print(labels.shape)\n",
    "print(np.zeros((10,28*28)).shape)\n",
    "print(len(labels))\n",
    "# 訓練データとテストデータ表示するところ\n",
    "\n",
    "image = cv2.imread(img)\n",
    "h,w,_ = image.shape[:3]\n",
    "disped_train_pos = np.zeros((w, h))\n",
    "disped_train_pos = dispCropPos(cv2.imread(img), t_test, dataset.getOnehotSize(),dataset.onehot_ratio)\n",
    "disped_test_pos = dispCropPos(disped_train_pos, train, dataset.getOnehotSize(),dataset.onehot_ratio, (167,81,168))\n",
    "fig = plt.figure() # Figureオブジェクトを作成\n",
    "plt.imshow(disped_test_pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
